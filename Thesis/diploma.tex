% Тут используется класс, установленный на сервере Papeeria. На случай, если
% текст понадобится редактировать где-то в другом месте, рядом лежит файл matmex-diploma-custom.cls
% который в момент своего создания был идентичен классу, установленному на сервере.
% Для того, чтобы им воспользоваться, замените matmex-diploma на matmex-diploma-custom
% Если вы работаете исключительно в Papeeria то мы настоятельно рекомендуем пользоваться
% классом matmex-diploma, поскольку он будет автоматически обновляться по мере внесения корректив
%
\documentclass{matmex-diploma}
\usepackage{amssymb}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{minted}
\usepackage{pdflscape}

\floatname{algorithm}{Алгоритм}
\renewcommand{\algorithmicrequire}{\textbf{Входные параметры:}}
\renewcommand{\algorithmicensure}{\textbf{Результат:}}

\AtBeginDocument{%
  \def\postsection{\@\ }%
  \def\postsubsection{\@\ }%
  \def\postsubsubsection{\@\ }%
  \def\postparagraph{\@\ }%
  \def\postsubparagraph{\@\ }%
}


\begin{document}
% Год, город, название университета и факультета предопределены,
% но можно и поменять.
% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
\filltitle{ru}{
    chair              = {Кафедра Информационных Систем},
    title              = {Реализация эффективного выполнения поисковых запросов по множеству полей для колоночно-ориентированной базы данных, хранящейся в памяти.},
    % Здесь указывается тип работы. Возможные значения:
    %   coursework - Курсовая работа
    %   diploma - Диплом специалиста
    %   master - Диплом магистра
    %   bachelor - Диплом бакалавра
    type               = {bachelor},
    position           = {студента},
    group              = {4501},
    author             = {Жаворонков Эдгар Андреевич},
    %supervisorPosition = {д.\,ф.-м.\,н., профессор},
    supervisor         = {Дельгядо Ф.\,И.},
    reviewerPosition   = {к.\,т.\,н., доцент каф. КОТ},
    reviewer           = {Белозубов А.\,В.},
    chairHeadPosition  = {д.\,т.\,н., профессор},
    chairHead          = {Парфёнов В.\,Г.},
    university         = {Санкт-Петербургский Национальный Исследовательский Университет Информационных Технологий, Механики и Оптики},
    faculty            = {Факультет Информационных Технологий и Программирования},
    city               = {Санкт-Петербург},
    year               = {2015}
}
\maketitle
%\includepdf[pages={-}]{../docs/Title.pdf}
\setcounter{page}{4}
\tableofcontents

% У введения нет номера главы
\section*{Термины и сокращения}

    \textbf{БД} - База данных — Совокупность данных, организованных в соответствии с концептуальной структурой, описывающей характеристики этих данных и взаимоотношения между ними, причём такое собрание данных, которое поддерживает одну или более областей применения. - \cite{iso:iec:2382}
    
    \textbf{СУБД} - Система управления базами данных - Совокупность программных и лингвистических средств общего или специального назначения, обеспечивающих управление созданием и использованием баз данных. - \cite{gost10032}
    
    \textbf{In-Memory Database} - База данных, лежащая в памяти - База данных, полностью использующая в своей работе оперативную память, а не жёсткий диск компьютера. - \cite{vizard}  
    
    \textbf{OLAP} - online analytical processing, аналитическая обработка в реальном времени — технология обработки данных, заключающаяся в подготовке суммарной (агрегированной) информации на основе больших массивов данных, структурированных по многомерному принципу. - \cite{gartner}
    
    \textbf{Байт-код} - набор инструкций виртуальной машины Java. - \cite{jvm:spec}
    
    \textbf{Рефакторинг} - процесс изменения внутренней структуры программы, не затрагивающий её внешнего поведения и имеющий целью облегчить понимание её работы. - \cite{fowler}
    
    \textbf{Статический анализ кода} - анализ программного обеспечения, производимый (в отличие от динамического анализа) без реального выполнения исследуемых программ. - \cite{wichmann1995industrial}
    
    \textbf{Фреймворк}(англ. Framework) - программная платформа, определяющая структуру программной системы; программное обеспечение, облегчающее разработку и объединение разных компонентов большого программного проекта. - \cite{wiki:framework}
    
    \textbf{Репозиторий} - cредство для хранения описания и поведения объектов на предприятии, в том числе требований, политик, процессов, данных, программных библиотек, проектов, платформ и персонала, с возможностью поддержки как разработки программного обеспечения, так и управления операциями. - \cite{gartner}
    
\section*{Введение}
    Середина 2000-ых годов ознаменовалось ростом производительности аппаратного обеспечения и, как следствие, развитием колоночно-ориентированных баз данных. В данной работе предполагается описание и реализация алгоритмов выполнения поисковых запросов к такой базе.
    
    В первой главе будет проанализирована предметная область, описана общая архитектура колоночно ориентированных баз данных и их отличие от традиционных решений. Предполагается формальная постановка задачи, описание требований к решению и рассмотрение аналогичных решений.
    
    Во второй главе предполагается формальное описание алгоритмов выполнения поисковых запросов, а также - описание подходов к выполнению атомарного добавления записей в такую базу.
    
    В третьей главе представлено описание технологической платформы, на которой реализованы описанные в первой главе алгоритмы. Так же предполагается описание тестовой инфраструктуры, постановка задачи тестирования и описание полученных результатов.
    
\section{Анализ предметной области}
    \subsection{Краткая история и архитектура колоночно-ориентированных баз данных}
        \paragraph{Историческая справка}
            Колоночно-ориентированные системы управления базами данных берут своё начало в 70-ых годах прошлого столетия. Самой первой из них можно назвать TOD (Time Oriented Database), основное предназначение которой было управление медицинскими записями. Одна из ранних систем, напоминающих современные колоночно-ориентированные СУБД была Cantor, которая, кроме всего прочего, включала в себя обильное использование различных техник сжатия данных (RLE - Run Length Encoding, сжатие числовых данных и т.д). Дальнейшее развитие привело к появлению на свет Sybase IQ, показавшей преимущества колоночно-ориентированного хранения данных для аналитических приложений. В середине 2000-ых годов, в связи с увеличением производительности аппаратного обеспечения, произошел резкий скачок в развитии колоночно-ориентированных хранилищ. На свет появились Vertica, Ingres, VectorWise, Paraccel и др. В дальнейшем, это привело к тому, что многие большие разработчики традиционных реляционных БД (такие как Oracle, Microsoft, IBM и др.) добавили поддержку хранения данных по колонкам. - \cite{abadidesign}
        \paragraph{Краткое описание архитектуры}
            Главное отличие колоночно-ориентированных баз данных от традиционных - это физический способ хранения данных. Традиционные базы хранятся построчно, то есть все данные одной таблицы представлены в виде одной большой физической записи, в которой поля идут одно за другим.
        Плюсы такого подхода к хранению данных:
        \begin{enumerate}
            \item Быстрое добавление новых строк в таблицу;
            \item Быстрая выборка строки по ключу;
            \item Быстрая выборка всех строк;
        \end{enumerate}
        Минусы:
        \begin{enumerate}
            \item Медленная выборка нескольких колонок;
            \item Медленная вставка новой колонки;
            \item Избыточное хранение данных для полупустых колонок;
        \end{enumerate}
        
        Рассмотрим подробнее первый недостаток. Представим себе базу данных, состоящую из одной таблицы в 50 колонок. Предположим, что нам нужно выбрать из неё лишь три. Но тогда, так как она хранится построчно, то значения всех полей будут считаны с диска, затем ненужные данные будут отброшены. Получение этой выборки произойдёт за время равное $O(m * n)$, где $m$ - это количество строк, а $n$ - количество колонок. При большом количестве строк в такой базе, получение выборки по нескольким критериям - довольно дорогая операция, особенно с учётом ограничений дисковых интерфейсов ввода-вывода. - \cite{habr:column_db}
        
        \begin{figure}[h]
            \centering
            \includegraphics[width=\textwidth]{../pics/row_store.png}
            \caption{Чтение всех столбцов из строчной БД}
            \label{row_store}
        \end{figure}
        
        \begin{figure}[h]
            \centering
            \includegraphics[width=\textwidth]{../pics/column_store.png}
            \caption{Чтение всех столбцов из колоночной БД}
            \label{column_store}
        \end{figure}
        
        Колоночно-ориентированные базы данных хранят записи по колонкам, друг за другом.  Очевидны плюсы такого формата хранения данных:
        \begin{enumerate}
            \item Возможность сжатия данных;
            \item Быстрая вставка новой колонки или изменение значений в существующей;
            \item Быстрая выборка нескольких колонок;
            \item Быстрое вычисление агрегирующих функций от значений в колонке;
        \end{enumerate}
        Но есть и минус:
        \begin{enumerate}
            \item Изменение нескольких значений в строке происходит медленнее, чем у традиционных БД;
        \end{enumerate}
    \paragraph{Решаемые задачи} 
        Из плюсов и минусов колоночно-ориентированных баз напрямую следуют задачи, которые они призваны решать. Как я уже упоминал в истории развития, такой подход к хранению данных хорош для аналитических приложений, в которых основная нагрузка создаётся выборкой больших объёмов данных по нескольким критериям. Либо же, задача многокритериального поиска, в которой, опять же, основная нагрузка - выборка большого объёма данных по нескольким полям, но уже без какой-либо аналитики.
        \begin{figure}[h]
            \centering
            \includegraphics[width=\textwidth]{../pics/column-oriented-database1.jpg}
            \caption{Различия в способе хранения данных в традиционных и колоночно-ориентированных БД}
            \label{architecture_diff}
        \end{figure}
    \subsection{Постановка задачи}
        Целью данной работы является разработка компонента для базы данных, предназначенной для эффективной реализации поиска по большому количеству критериев. Подобная база данных может использоваться для большого количества разнообразных задач, в первую очередь для организации поиска по товарам в больших торговых площадках (wikimart.ru - 1.8 млн товаров, Яндекс.Маркет - 57 млн. предложений, amazon.com - 36 млн книг). Для подобных задач характерен поиск по большому количеству критериев (около ста для одного предложения Яндекс.Маркета, двадцати - для amazon.com) и разнообразные принципы поиска по критериям (поиск по диапазону, по совпадению, полнотекстовый поиск). Задача осложняется неравномерным распределением критериев в данных и потенциально большими размером результирующих выборок. При этом, к базе данных предъявляются высокие требования к производительности (как к нагрузке, так и к скорости получения результата) а так же - необходимость обеспечения целостности данных при массовых изменениях значения одного или нескольких критериев. Яркий пример такой ситуации - изменение цен в интернет-магазине в следствие скачка цен или резком изменении курса валюты.
    \subsection{Требования к разрабатываемому решению}
        Отправной точкой данной работы являются требования, предъявляемые к разрабатываемому решению. Требования появились в результате взаимодействия с руководителем.
        \subsubsection{Функциональные требования}
            \begin{enumerate}
                \item Планирование порядка выполнения запроса;
                \item Учёт сложности запросов к сложным хранилищам (полнотекстовый поиск и т.п.);
                \item Возможность автоматической настройки исполнителя запросов;
                \item Реализация корректного выполнения запросов на массированных изменениях данных;
            \end{enumerate}
        \subsubsection{Формальные показатели}
            \begin{enumerate} 
                \item Уменьшение времени выполнения отдельных запросов в два и более раз;
            \end{enumerate}
        \subsubsection{Нефункциональные требования}
            \begin{enumerate} 
                    \item Низкие накладные расходы на обеспечение эффективности выполнения запросов;
                    \item Тестирование правильности функционирования выполнения запросов;
            \end{enumerate}
    \subsection{Обзор аналогов}
        Ближайшие по архитектуре СУБД - это TimesTen by Oracle, VoltDB и SAP HANA. Все три используют хранение данных по колонкам, являются in-memory и предназначены для аналитических задач. Однако, их объединяет один общий недостаток - цена. Полные версии каждой из этих СУБД стоят больше десяти тысяч долларов США.
    
    Существует бесплатный вариант in-memory SQL базы данных - H2. Однако, он не колоночно-ориентирован и медленно работает на сложных операциях JOIN.
    
    Существуют два бесплатных решения, пригодных для решения задач многокритериального поиска - это MySQL и Lucene. Вообще говоря, основное предназначение Apache Lucene - это полнотекстовый поиск, однако им можно пользоваться и как in-memory БД для поиска по многим критериям. Недостаток Lucene - очень медленная операция изменения данных. Недостатки MySQL - плохая оптимизация поиска по нескольким индексам с последующим пересечением результатов и ограниченные возможности in-memory версии. 
    
    \begin{table}[h]
        \centering
        \caption{Сравнительная характеристика TimesTen, VoltDB и SAP HANA}
        \begin{tabular}{| l | c | c | c | c |}
            \hline
            Product & in-memory & NoSQL & OLAP & Price \\
            \hline
            Oracle TimesTen & \color{green}{\checkmark} & \color{green}{\checkmark} & \color{green}{\checkmark} & \color{red}{€19,969.00} \\
            \hline 
            VoltDB          & \color{green}{\checkmark} & \color{green}{\checkmark} & \color{green}{\checkmark} & \color{red}{\$3500/month} \\
            \hline
            SAP HANA        & \color{green}{\checkmark} & \color{green}{\checkmark} & \color{green}{\checkmark} & \color{red}{\$3595/month}\\
            \hline
        \end{tabular}
    \end{table}
    
    \subsection{Выводы по первой главе}
        В первой главе проведён анализ предметной области, установлена цель и поставлены задачи работы. Представлена краткая историческая справка и общее описание архитектуры колоночно-ориентированных баз данных. Приведено описание аналогов, отмечены их достоинства и недостатки.
    
\section{Описание проектных решений}
    \subsection{Описание системной архитектуры модифицируемого решения}
    Система управления базами данных Vindur представляет собой легко расширяемую встраиваемую NoSQL базу данных, имеющую колоночно-ориентированную архитектуру, хранящую данные в оперативной памяти. Задача, решаемая с помощью Vindur - это быстрый поиск по многим критериям. 
    Основные сущности и компоненты Vindur:
        \begin{enumerate}
            \item \textbf{Документ}(Document) - основная сущность, хранящаяся в базе данных. Представляет собой набор атрибутов и соответствующих значений. Каждый документ обладает уникальным идентификационным номером.                 
            \item \textbf{Хранилище}(Storage) - структура данных, хранящая в удобном для требуемого типа запроса формате значения отдельно взятого атрибута для всех документов. Поддерживает операции поиска и изменения значения в отдельно взятом документе. Также поддерживает операцию поиска всех документов с заданным значением атрибута.
            \item \textbf{Запрос}(Query) - набор критериев к документу, которым он должен соответствовать для включения в результирующую выборку. Формально - множество пар $(a, v)$, где $a$ - атрибут, а $v$ - его значение. 
            \item \textbf{Результат запроса}(Query result) - множество документов, удовлетворяющих данному запросу-выборке.
            \item \textbf{Вес хранилища}(Complexity) - эмпирическая оценка относительной трудоёмкости запроса к данному хранилищу.
            \item \textbf{Движок базы данных}(Engine) - главный компонент всей системы, хранящий в себе документы, хранилища и содержащий методы для добавления нового документа, изменения значения выбранного атрибута в отдельно взятом документе, а также - выполнения запросов-выборок.
            \item \textbf{Исполнитель}(Executor) - компонент базы данных, осуществляющий исполнение поисковых запросов.
        \end{enumerate}
    
    Основной единицей хранения в Vindur является документ - набор полей(атрибутов) и соответствующих значений атрибутов. Каждый атрибут может иметь одно или несколько значений. Кроме того, документ обладает уникальным идентификационным номером, по которому движок базы данных обращается к нему. 
    
    Значения каждого атрибута хранятся независимо в специально предназначенных хранилищах. Каждое хранилище ориентировано для выполнения определённого вида запросов(поиск по точному совпадению, поиск на попадание в диапазон, полнотекстовый поиск) к нему. Иначе говоря, для каждого атрибута можно указать только один тип критерия, на который он будет проверяться. На данный момент реализованы критерии ''точное соответствие'', ''включён в диапазон'', ''соответствует маске'', ''входит в иерархию''. 
    
    По своей структуре, хранилище представляет собой набор битовых массивов. Результат запроса к хранилищу - битовый массив, в котором единица в $i$-ой позиции означает, что в документе с номером $i$ значение данного атрибута соответствует запросу. Битовые массивы используются по ряду причин, основная из которых - возможность сжатия. Кроме того, операции пересечения множеств документов, удовлетворяющих различным критериям соответствует операция логического ''И'', выполненная для соответствующих битовых массивов.
    
    Основная причина, по которой Vindur использует битовые массивы - это возможность сжатия. Сжатие позволяет экономно использовать оперативную память компьютера, что важно, так как Vindur позиционируется как In-Memory база данных. Кроме того, сжатые битовые массивы помещаются в кэш-память ядер процессора, что позволяет очень быстро выполнять логические операции над ними. 
    
    Рассмотрим процесс выполнения поискового запроса к базе данных Vindur. Он состоит из двух этапов - проверки на корректность(для всех атрибутов проверяется, можно ли к данному хранилищу выполнить запрос такого типа) и непосредственно выполнения. Выполнение заключается в последовательном получении битовых массивов из хранилищ с последующим пересечением. На данный момент реализованы три стратегии выполнения поисковых запросов:
    \begin{enumerate}
        \item Тривиальная стратегия (так называемый алгоритм DumbExecutor)
        \item Стратегия выполнения запроса с весами хранилищ (алгоритм SmartExecutor)
        \item Стратегия выполнения запросов на основе статистики по атрибутам (алгоритм TunableExecutor)
    \end{enumerate}
    
    \begin{figure}[H]
        \label{query}
        \centering
        \includegraphics[width=0.5\textwidth]{../pics/query.png}
        \caption{Общая схема выполнения поискового запроса в СУБД Vindur}
    \end{figure}
    %а нужен ли?????
    %\pagebreak
    \subsection{Описание тривиального исполнителя запросов}
        Алгоритм DumbExecutor принимает на вход поисковый запрос $Q$, разбивает его на части $\left\{ q_1, q_2, q_3, ... , q_n \right\} $ и для каждой части выполняет операцию обращения к хранилищу, содержащему данные по данному атрибуту. Выход алгоритма - список номеров документов, удовлетворяющих все критериям в запросе. Псевдокод алгоритма выглядит следующим образом.
        \begin{algorithm}                   
        \caption{DumbExecutor}              
        \label{dumb}                        
            \begin{algorithmic}        
                \REQUIRE $Q$ - запрос
                \ENSURE $resultSet$ - множество документов, удовлетворяющих запросу $Q$
                \STATE $\left\{ q_1, q_2, q_3, ... , q_n \right\} \leftarrow SplitIntoParts(Q);$
                \STATE $resultSet \leftarrow NULL;$
                \FOR{$ i \in \{1..n\}$}
                    \STATE $a \leftarrow Attribute(q_i);$
                    \STATE $v \leftarrow Value(q_i);$
                    \STATE $stepResult \leftarrow FindSet(a, v);$
                    \IF{$resultSet = NULL$}
                        \STATE $resultSet \leftarrow stepResult;$
                    \ENDIF
                    \STATE $resultSet \leftarrow resultSet \land stepResult;$
                \ENDFOR
                \RETURN $ConvertToIntList(resultSet);$
            \end{algorithmic}
        \end{algorithm}
        
        Функция $SplitIntoParts$ принимает на вход запрос $Q$ и возвращает список всех частей запроса. Функции $Attribute$ и $Value$ принимают на вход часть запроса $q$ и возвращают соответственно атрибут и значение, хранящиеся в данной части запроса. Функция $findSet$ принимает на вход атрибут и значение и возвращает битовую массив - результат обращения к соответствующему хранилищу. В данном случае $resultSet $ и $stepResult$ - это битовые массивы. Функция $ConvertToIntList$ принимает на вход битовый массив $mask$ и возвращает список позиций, таких что $mask_i = 1$ 
        
    \subsection{Описание исполнителя запросов с весами}
        Алгоритм SmartExecutor принимает на вход поисковый запрос $Q$, разбивает его на части $\left\{ q_1, q_2, q_3, ... , q_n \right\} $ и ставит в соответствие каждому атрибуту из частей запроса вес хранилища. После этого, он обращается к хранилищам в порядке увеличения весов хранилищ. Кроме запроса, алгоритм принимает на вход размер результирующей выборки, начиная с которого проверка документов на соответствие критериям запроса происходит в обход хранилищ - так называемый порог срабатывания. Выход алгоритма - так же список номеров документов, удовлетворяющих все критериям в запросе. В данном случае веса хранилищ устанавливаются эмпирически. Псевдокод самого алгоритма выглядит следующим образом:
        \begin{algorithm}[H]                   
        \caption{SmartExecutor}              
        \label{smart}                        
            \begin{algorithmic}        
                \REQUIRE $Q$ - запрос, $threshold$ - порог срабатывания
                \ENSURE $resultSet$ - множество документов, удовлетворяющих запросу $Q$
                \STATE $\left\{ q_1, q_2, q_3, ... , q_n \right\} \leftarrow SplitIntoParts(Q);$
                \STATE $Sort(\left\{ q_1, q_2, q_3, ... , q_n \right\}, Compare);$
                \STATE $resultSet \leftarrow NULL;$
                \FOR{$ i \in \{1..n\}$}
                    \STATE $a \leftarrow Attribute(q_i), v \leftarrow Value(q_i);$
                    \STATE $stepResult \leftarrow FindSet(a, v);$
                    
                    \IF{$resultSet = NULL$}
                        \STATE $resultSet \leftarrow stepResult;$
                    \ELSE
                        \STATE $resultSet \leftarrow resultSet \land stepResult;$
                    \ENDIF
                    
                    \IF{$Cardinality(resultSet) = 0$}
                        \RETURN $EMPTY\_LIST;$
                    \ENDIF
                    
                    \IF{$Cardinality(resultSet) \leq threshold$}
                        \STATE $tail \leftarrow \left\{ q_1, q_2, q_3, ... , q_n \right\} \setminus \left\{ q_1, q_2, q_3, ... , q_i \right\};$
                        \RETURN $CheckManually(tail, resultSet);$
                    \ENDIF
                \ENDFOR
                \RETURN $ConvertToIntList(resultSet);$
            \end{algorithmic}
        \end{algorithm}
        
        Функция $Sort$ принимает на вход части $\left\{ q_1, q_2, q_3, ... , q_n \right\}$ запроса $Q$ и сортирует их по убыванию весов соответствующих хранилищ. Для этого, вторым параметром она принимает компаратор - функцию сравнения двух частей запроса, которая возвращает $-1$, если хранилище для атрибута $a_1$ имеет меньший вес, чем хранилище для атрибута $a_2$, $0$ - если веса хранилищ равны, $1$ - в противном случае. Функция $Complexity$ принимает на вход атрибут и возвращает вес хранилища, ассоциированного с данным атрибутом. Функция $Cardinality$ принимает на вход битовый массив и возвращает количество единичных бит в нём. 
        \begin{algorithm}[H]                   
        \caption{Compare}              
        \label{cmp}                        
            \begin{algorithmic}        
                \REQUIRE $q_1$, $q_2$ - части запроса
                \ENSURE Результат сравнения по весам хранилищ двух частей запроса
                \STATE $a_1 \leftarrow Attribute(q_1);$
                \STATE $a_2 \leftarrow Attribute(q_2);$
                \IF {$Complexity(a_1) < Compexity(a_2)$}
                    \RETURN $-1;$
                \ELSE 
                    \IF {$Complexity(a_1) = Compexity(a_2)$}
                        \RETURN $0;$
                    \ELSE
                        \RETURN $1;$
                    \ENDIF
                \ENDIF
            \end{algorithmic}
        \end{algorithm}
        
        Функция $CheckManually$ осуществляет проверку документов на соответствие оставшимся критериям в запросе $Q$ в обход хранилищ. На вход подаётся текущая результирующая выборка и оставшиеся части $\left\{ q_1, q_2, q_3, ... , q_n \right\} \setminus \left\{ q_1, q_2, q_3, ... , q_i \right\}$ запроса $Q$. На выходе - cписок номеров документов, удовлетворяющим всем критериям из запроса $Q$. Соответсвующий псевдокод:
        
        \begin{algorithm}[H]                   
        \caption{CheckManually}              
        \label{check}                        
            \begin{algorithmic}        
                \REQUIRE $tail$ - оставшиеся части запроса, $currentResultSet$ - результирующая выборка
                \ENSURE $resultSet$ - множество документов, удовлетворяющих оставшимся частям запроса $tail$
                \STATE $resultSet \leftarrow NULL;$
                \FOR {$q \in tail$}
                    \STATE $stepResult \leftarrow EMPTY\_SET;$
                    \FOR {$docID \in ConvertToIntList(currentResultSet)$}
                        \STATE $a \leftarrow Attribute(q);$
                        \STATE $v \leftarrow Value(q);$
                        \STATE $values \leftarrow getValues(getDocument(docID), a);$
                        \IF {$v \in values$}
                            \STATE $stepResult_{docID} \leftarrow 1;$
                        \ENDIF
                    \ENDFOR
                    \IF {$resultSet = NULL$}
                        \STATE $resultSet \leftarrow stepResult;$
                    \ENDIF
                    \STATE $resultSet \leftarrow resultSet \land stepResult;$
                \ENDFOR
                \STATE $resultSet \leftarrow resultSet \land currentResultSet;$
                \RETURN $ConverToIntList(resultSet);$
            \end{algorithmic}
        \end{algorithm}
        
    \subsection{Описание автоматически настраивающегося исполнителя}
        %рассказать про дополнительный поток в движке, про тюнер, про очередь запросов, затем рассказать про журнал статистики и потом только про исполнение 
        Алгоритм TunableExecutor использует параллельный поток исполнения, в котором считается среднее время выполнения запроса к хранилищу. Рассмотрим подробнее его работу.
        
        Еще одна сущность Vindur - это так называемый \textbf{настройщик}(Tuner). Это компонент, собирающий статистические данные для всех атрибутов. Статистические данные включают в себя среднее время выполнения операции $FindSet$  к хранилищу и среднее время проверки значения атрибута в документе напрямую.
        
        При инициализации движка базы данных происходит создание и запуск параллельного потока, который в бесконечном цикле вызывает операцию $CallTuner$ один раз в секунду.
        
        При исполнении поискового запроса перед проверкой на корректность происходит добавление запроса в очередь. Настройщик извлекает последний запрос, попавший в очередь и для каждого атрибута в запросе измеряет среднее время выполнения операции $findSet$  к хранилищу и среднее время проверки значения атрибута в документе напрямую. Результаты сохраняются в специальный журнал, доступный как и потоку, в котором работает настройщик, так и потоку, в котором работает исполнитель запросов.
        
        Соответственно, алгоритм TunableExecutor принимает на вход поисковый запрос $Q$, разбивает его на части $\left\{ q_1, q_2, q_3, ... , q_n \right\} $ и ставит в соответствие каждому атрибуту из частей запроса среднее время выполнения операции $findSet$, если же по каким-либо причинам статистических данных нет, то в соответствие атрибуту ставится вес хранилища. После этого, он обращается к хранилищам в порядке увеличения среднего времени выполнения. 
        
        Кроме того, алгоритм на каждом шаге считает, какое время займёт ручная проверка оставшихся критериев в запросе. Если получится так, что проверка в обход хранилищ окажется быстрее, то алгоритм проверит текущую результирующую выборку на соответствие остальным критериям в запросе напрямую. Выход алгоритма - так же список номеров документов, удовлетворяющих все критериям в запросе. Привдем псевдокод некоторых вспомогательных функций:
        \begin{algorithm}[H]
        \caption{TunerThread}
        \label{tunerThread}
            \begin{algorithmic}
                \WHILE {TRUE}
                    \STATE $callTuner();$
                    \STATE $Sleep(1000);$
                \ENDWHILE
            \end{algorithmic}
        \end{algorithm}
        
        \begin{algorithm}[H]
        \caption{InitEngine}
        \label{init}
            \begin{algorithmic}
                \STATE $StartThread(TunerThread);$
            \end{algorithmic}
        \end{algorithm}
        
        \begin{algorithm}[H]
        \caption{ExecuteQuery}
        \label{exec}
            \begin{algorithmic}
                \REQUIRE $Q$ - поисковый запрос
                \ENSURE $resultSet$ - множество документов, удовлетворяющих запросу $Q$
                \STATE $push(Q, queries);$
                \STATE $CheckQuery(Q);$  
                \RETURN $TunableExecutor(Q);$
            \end{algorithmic}
        \end{algorithm}
        
        \begin{algorithm}[H]                   
        \caption{Compare}              
        \label{cmp1}                        
            \begin{algorithmic}        
                \REQUIRE $q_1$, $q_2$ - части запроса $journal$ - журнал, хранящий статистические данные по атрибутам
                \ENSURE Результат сравнения двух частей запроса
                \STATE $a_1 \leftarrow Attribute(q_1)$
                \STATE $a_2 \leftarrow Attribute(q_2)$
                \IF {$ExecutionTime(journal, a_1) < ExecutionTime(journal, a_2)$}
                    \RETURN $-1;$
                \ELSE 
                    \IF {$ExecutionTime(journal, a_1) = ExecutionTime(journal, a_2)$}
                        \RETURN $0;$
                    \ELSE
                        \RETURN $1;$
                    \ENDIF
                \ENDIF
            \end{algorithmic}
        \end{algorithm}
        
        Функция $CallTuner$ проверяет, не пуста ли очередь запросов $queries$, если она не пуста - она извлекает из очереди запрос и для каждого атрибута в запросе считает среднее время выполнения операции $findSet$ и прямой проверки, записывая данные в специальный журнал $journal$. Процедура $StartThread$, запускает параллельный поток $TunerThread$.
        
        Функция $GetJournal$ возвращает журнал, содержащий статистические данные для атрибутов, по которым настройщик измерял среднее время выполнения. Функции $ExecutionTime$ и $CheckTime$ принимают на вход журнал статистики и атрибут и возвращают среднее время обращения к хранилищу и среднее время проверки значения в документе соответственно. Функция $Compare$ точно так же осуществляет сортировку множества частей запроса $Q$ по возрастанию среднего времени обращения к соответствующим хранилищам.
        
        Функция $ExecuteQuery$ - это полный алгоритм выполнения поискового запроса с проверкой на корректность и добавлением запроса $Q$ в очередь $queries$. Псевдокод самого алгоритма имеет следующий вид:
        
        \begin{algorithm}[H]                   
        \caption{TunableExecutor}              
        \label{tunable}                        
            \begin{algorithmic}        
                \REQUIRE $Q$ - запрос
                \ENSURE $resultSet$ - множество документов, удовлетворяющих запросу $Q$
                \STATE $\left\{ q_1, q_2, q_3, ... , q_n \right\} \leftarrow SplitIntoParts(Q);$
                \STATE $journal \leftarrow GetJournal();$
                \STATE $Sort(\left\{ q_1, q_2, q_3, ... , q_n \right\}, Compare);$
                \STATE $resultSet \leftarrow NULL;$
                
                \STATE $estimatedExecutionTime \leftarrow 0;$
                \FOR {$ i \in \{1..n\} $}
                    \STATE $a \leftarrow Attribute(q_i);$
                    \STATE $estimatedExecutionTime = estimatedExecutionTime + ExecutionTime(journal, a);$
                \ENDFOR
                
                \FOR {$ i \in \{1..n\} $}
                    \STATE $a \leftarrow Attribute(q_i);$
                    \STATE $v \leftarrow Value(q_i);$
                    \STATE $stepResult \leftarrow FindSet(a, v);$
                    \STATE $estimatedExecutionTime \leftarrow estimatedExecutionTime - ExecutionTime(journal, a);$
                    \IF{$resultSet = NULL$}
                        \STATE $resultSet \leftarrow stepResult;$
                    \ELSE
                        \STATE $resultSet \leftarrow resultSet \land stepResult;$
                    \ENDIF
                    \STATE $partsLeft \leftarrow n - i;$
                    \IF{$Cardinality(resultSet) = 0$}
                        \RETURN $EMPTY\_LIST;$
                    \ENDIF
                    \STATE $estimatedCheckTime \leftarrow partsLeft * CheckTime(journal, a);$
                    \IF{$estimatedCheckTime \leq estimatedExecutionTime$}
                        \STATE $tail \leftarrow \left\{ q_1, q_2, q_3, ... , q_n \right\} \setminus \left\{ q_1, q_2, q_3, ... , q_i \right\}$
                        \RETURN $CheckManually(tail, resultSet);$
                    \ENDIF
                \ENDFOR
                \RETURN $ConvertToIntList(resultSet;)$
            \end{algorithmic}
        \end{algorithm}

    \subsection{Описание первого варианта атомарного изменения документа}
        \paragraph{Мотивация} В распределённых системах важным моментом является поддержка согласованности данных. В рамках данной работы, поддержка согласованности данных сводится к возможности атомарно изменять значения в документах. Существует целая теория, описывающая модели и подходы к обеспечению согласованности. В рамках данной теории вводится понятие транзакции и рассматриваются некоторые свойства, которыми должны обладать транзакции, чтобы обеспечить согласованность данных между ними. 
        
        Согласно \cite{novikov}, транзакцией называется совокупность операций, переводящая систему из одного согласованного состояния в другое при выполнении двух условий:
        \begin{enumerate}
            \item Нет помех со стороны других приложений
            \item Последовательность операций выполнена полностью
        \end{enumerate}
        
        В данной работе приведено описание двух вариантов реализации атомарного изменения значения в документе. Первый вариант предполагает три операции.
        \begin{enumerate}
            \item $StartTransaction$ - начинает сеанс массового обновления значений и возвращает уникальный идентификатор сеанса 
            \item $CommitTransaction$ - Подтверждает все изменения и применяет их к записям в базе данных
            \item $RollBackTransaction$ - Отменяет текущий сеанс и откатывает все изменения, возвращая базу в исходное состояние.
        \end{enumerate}    
        Рассмотрим более подробно, как происходят все три операции. Операция $StartTransaction$ не принимает ничего на вход, но, при этом, внутри себя генерирует уникальный идентификатор сеанса и создаёт запись в специальном журнале. Пользователю возвращается идентификатор сеанса. Псевдокод выглядит следующим образом:
            
        \begin{algorithm}[H]                   
        \caption{StartTransaction}              
        \label{startTran1}                        
            \begin{algorithmic}        
                \ENSURE $transactionID$ - уникальный идентификатор сеанса
                \STATE $transactionID \leftarrow GenerateBigRandomNumber();$
                \STATE $PutNewRecord(transactionID);$
                \RETURN $transactionID;$
            \end{algorithmic}
        \end{algorithm}
        
        Операция $CommitTransaction$ принимает на вход идентификатор сеанса, блокирует движок базы данных и применяет изменения, записанные в журнал. Псевдокод имеет следующий вид:
        
        \begin{algorithm}[H]                   
        \caption{CommitTransaction}              
        \label{commitTran1}                        
            \begin{algorithmic}
                \REQUIRE $transactionID$ - уникальный идентификатор сеанса
                \STATE $LockEngine();$
                \STATE $ operations \leftarrow GetOperations(transactionID);$
                \FOR {$operation \in operations$}
                    \STATE $docID \leftarrow DocumentId(operation);$
                    \STATE $attr \leftarrow Attribute(operation);$
                    \STATE $val \leftarrow Value(opearion);$
                    \STATE $SetValue(docID, attr, val);$
                \ENDFOR
                \STATE $UnlockEngine();$
            \end{algorithmic}
        \end{algorithm}
        
        Процедуры $LockEngine$ и $UnlockEngine$ осуществляют блокировку движка базы данных, чтобы ни один параллельный поток не мог вмешать в процесс применения изменений. Функция $GetOperations$ принимает на вход идентификатор сеанса и возвращает список всех операций изменения значения в документах. Функции $DocumentId$, $Attribute$ и $Value$ принимают на вход операцию изменения и возвращают номер документа, атрибут и значение соответственно. Процедура $SetValue$ принимает на вход номер документа, атрибут и его новое значение и устанавливает в документе с соответствующим номером новое значение соответствующего атрибута.
        
        Отдельно написана процедура $SetValue'$, предназначенная для использования при массовой загрузке документов. Кроме номера документа, атрибута и значения, она принимает на вход ещё и номер сеанса массовой загрузки, в рамках которого должны быть приняты соответствующие изменения. Её псевдокод выглядит следующим образом:
        
        \begin{algorithm}[H]                   
        \caption{SetValue'}              
        \label{update}                        
            \begin{algorithmic}
                \REQUIRE $transactionID$ - уникальный идентификатор сеанса, $docID$ - номер документа, $attribute$ - атрибут, $value$ - новое значение атрибута
                \STATE $ AddOperation(transactionID, docID, attribute, value);$
            \end{algorithmic}
        \end{algorithm}
        
        Процедура $AddOperation$ принимает на вход идентификатор сеанса, номер документа, атрибут и его новое значение и добавляет в журнал запись об очередном изменении в рамках данного сеанса.
        
        Очевиден недостаток такого подхода к выполнению массовой загрузки документов - система простаивает при параллельных изменениях в следствие взаимных блокировок.
    \subsection{Описание второго варианта атомарного добавления документа}
        Второй вариант предполагает те же три операции, однако несколько иную логику их выполнения. В данном варианте после начала сеанса массового обновления значений в документах изменения записываются в журнал текущих изменений, но не применяются к документам. Затем по подтверждению, эти изменения начинают учитываться при выполнении поисковых запросов, но не применяются физически к базе данных. 
        Все изменения, требующие фиксации в хранилище (то есть сохранения значений после выполнения операции $CommitTransaction$) сохраняются в промежуточном хранилище.
        При каждом поисковом запросе, перед возвратом результирующей выдачи поискового запроса, движок базы данных проверяет, нет ли среди добавленных изменений тех, которые могут повлиять на результирующую выдачу. Если такие изменения есть, то результирующая выборка модифицируется(из неё либо удаляются более неактуальные документы, либо добавляются новые). 
        
        Кроме того, выполняется параллельный процесс фиксации данных, который применяет операции из промежуточного хранилища и, по мере выполнения фиксации, очищает данные в промежуточном хранилище.
        
        Операция отката в данном случае просто очищает список текущих изменений. Псевдокод операций имеет следующий вид:
        
        \begin{algorithm}[H]                   
        \caption{StartTransaction}              
        \label{startTran2}                        
            \begin{algorithmic}        
                \ENSURE $transactionID$ - уникальный идентификатор сеанса
                \STATE $transactionID \leftarrow GenerateBigRandomNumber();$
                \STATE $PutNewRecord(transactionID);$
                \RETURN $transactionID;$
            \end{algorithmic}
        \end{algorithm}
        
        \begin{algorithm}[H]                   
        \caption{CommitTransaction}              
        \label{commitTran2}                        
            \begin{algorithmic}
                \REQUIRE $transactionID$ - уникальный идентификатор сеанса
                \FOR {$operation \in currentChanges$}
                    \STATE $AddOperation(operation);$
                \ENDFOR
            \end{algorithmic}
        \end{algorithm}
        
        Б\'{о}льший интерес представляет процедура исполнения запроса. Приведём её псевдокод
        
        \begin{algorithm}[H]
        \caption{ExecuteQuery}
        \label{exec1}
            \begin{algorithmic}
                \REQUIRE $Q$ - поисковый запрос
                \ENSURE $resultSet$ - множество документов, удовлетворяющих запросу $Q$
                \STATE $push(Q, queries);$
                \STATE $CheckQuery(Q);$
                \STATE $resultSet \leftarrow TunableExecutor(Q);$
                \STATE $RunThread(ApplyChangesThread);$
                \FOR {$operation \in addedChanges$}
                    \STATE $docID \leftarrow DocumentId(operation);$
                    \STATE $attr \leftarrow Attribute(operation);$
                    \STATE $val \leftarrow Value(opearion);$
                    
                    \IF {$(attr, val) \in Q$}
                        \IF {$docID \notin resultSet$}
                            \STATE $Add(resultSet, docID);$
                        \ENDIF
                        
                    \ENDIF
                    
                    \IF {$attr \in Attributes(Q) \land val \neq GetValue(Q, attr) $}
                        \IF {$docID \in resultSet$}
                            \STATE $Remove(resultSet, docID);$
                        \ENDIF
                    \ENDIF
                \ENDFOR
                \STATE $JoinThread(ApplyChangesThread);$
                \STATE $Clear(addedChanges);$
                \RETURN $resultSet;$
            \end{algorithmic}
        \end{algorithm}
        
        Операции $Add$ и $Remove$ добавляют и, соответственно, удаляют из результирующей выборки документ по его номеру. Функция $Attributes$ принимает на вход поисковый запрос и возвращает множество всех атрибутов, имеющихся в запросе. Функция $GetValue$ принимает на вход запрос и атрибут и возвращает значение атрибута. Операция $Clear$ очищает журнал с добавленными изменениями. Процедуры $StartThread$ и $JoinThread$ запускают параллельный поток и, соответственно, дожидаются результатов его выполнения. Псевдокод функции $ApplyChangesThread$ приведён далее:
        
        \begin{algorithm}[H]
        \caption{ApplyChangesThread}
        \label{tranThread}
            \begin{algorithmic}
                \IF {$addedChanges \neq \emptyset$}
                    \FOR {$operation \in addedChanges$}
                        \STATE $docID \leftarrow DocumentId(operation);$
                        \STATE $attr \leftarrow Attribute(operation);$
                        \STATE $val \leftarrow Value(opearion);$
                        \STATE $SetValue(docID, attr, val);$
                    \ENDFOR
                \ENDIF
            \end{algorithmic}
        \end{algorithm}
        
        В рамках данного подхода к массовым изменениям значений в документах, псевдокод процедуры $SetValue'$ имеет следующий вид:
        
        \begin{algorithm}[H]                   
        \caption{SetValue'}              
        \label{update}                        
            \begin{algorithmic}
                \REQUIRE $transactionID$ - уникальный идентификатор сеанса, $docID$ - номер документа, $attribute$ - атрибут, $value$ - новое значение атрибута
                \STATE $operation \leftarrow (docID, attribute, value);$
                \STATE $Add(currentChanges, operation);$
                \STATE $AddOperation(transactionID, operation);$
            \end{algorithmic}
        \end{algorithm}
        
        В результате при выполнении длительных транзакций не происходит останова в работе системы. Аналогично, и при большом количестве небольших транзакций система не останавливается, хотя общая производительность и несколько уменьшается (за счёт затрат на поиск в хранилище промежуточных данных).
        
    \subsection{Выводы по второй главе}
        Во второй главе приведены формальные описания алгоритмов выполнения поисковых запросов и атомарного добавления документа. Приведён псевдокод алгоритмов. Блок-схемы алгоритмов выполнения поисковых запросов вынесены в приложения.
    
\section{Особенности реализации}
    \subsection{Описание технологической платформы}
        В качестве технологической платформы были выбраны следующие инструменты:
        \begin{enumerate}
            \item Языки программирования:
                \begin{enumerate}
                    \item Java 8;
                \end{enumerate}
            \item Система контроля версий:
                \begin{enumerate}
                    \item Git;
                \end{enumerate}
            \item Инфраструктура:
                \begin{enumerate}
                    \item Travis CI;
                    \item GitHub;
                \end{enumerate}
            \item Библиотеки и фреймворки:
                \begin{enumerate}
                    \item Java EWAH;
                    \item Apache Lucene;
                \end{enumerate}    
        \end{enumerate}
        
        Язык программирования Java 8 был выбран для использования по ряду причин:
        \begin{enumerate}
            \item Кроссплатформенность. Приложения, написанные на Java выполняются в так называемой виртуальной машине Java (Java Virtual Machine или JVM), на вход которой подаётся не исходный текст программы, а байт-код. Это позволяет запускать приложения на разных аппаратных платформах без перекомпиляции исходного кода.
            \item Богатая стандартная библиотека. Для Java существует огромное количество библиотек и фреймворков, расширяющих функциональность языка. Отдельно стоит отметить богатый выбор инструментов для написания многопоточных приложений(многопоточные контейнеры, примитивы синхронизации, etc).   
            \item Высокая производительность и эффективность байт-кода. Несмотря на расхожий стереотип, что время работы Java-приложений существенно больше, чем, например, у С++ приложений, механизм компиляции на лету(так называемой JIT, Just-In-Time компиляции) позволяет увеличивать производительность байт-кода.
            \item Высокий уровень абстракции. В восьмой версии языка Java среди нововведений имеются многочисленные функциональные интерфейсы, лямбда-выражения, позволяющие описывать некоторые конструкции(например код, выполняемый в параллельном потоке) меньшим числом строк кода. Код сразу становится более читаемым и понятным.  
            \item Удобная среда разработки. Отдельным пунктом стоит отметить наличие невероятно удобной среды разработки - IntelliJ IDEA. Она предлагает статический анализ кода, мощные инструменты рефакторинга , интеграцию с системами контроля версий. Также отдельно стоит отметить мощный отладчик с декомпилятором, позволяющий заглянуть внутрь компонентов стандартной библиотеки языка и вычислять сложные выражения во время отладки.
            \item Движок Vindur изначально был написан именно на Java
            
        Система контроля версий Git была выбрана по причине удобства интеграции в среду разработки, возможности практиковаться локально, не трогая глобальный репозиторий, и наличию механизма веток(branches). Представим себе ситуацию, когда один из разработчиков решил внести экспериментальный функционал в проект, либо же, решил написать решение одной из задач проекта другим способом. Без разделения проекта на ветки, есть риск нарушить стабильный процесс сборки проекта и, как следствие, увеличить общее время разработки. В моей работе, в частности, различные варианты атомарного добавления документа расположены в разных ветках, что позволяет мне переключаться между ними прямо в среде разработки и тестировать их.
        
        Два инфраструктурных решения - Travis CI и GitHub. Первое - сервер непрерывной сборки. Бесплатен, автоматически забирает исходный код из репозитория, собирает проект и запускает тесты. Процесс сборки запускается при каждой фиксации изменений исходного кода в репозитории. Второе - хостинг с репозиторием, где лежат исходные файлы проекта. 
        
        Java EWAH - единственная библиотека на Java, реализующая сжатие битовых массивов. Apache Lucene - библиотека для полнотекстового поиска, написанная на Java.
        \end{enumerate}
    \subsection{Реализация тестовой инфраструктуры}
        Тестирование преследовало две цели:
            \begin{enumerate}
                \item Определить среднее время исполнения одного запроса в серии из большого числа друг за другом идущих запросов;
                \item Убедиться, что различные исполнители на одних и тех же данных и на одних и тех же запросах возвращают одинаковую результирующую выдачу;
            \end{enumerate}
            
        Для этого был создан движок базы данных. Были созданы три хранилища разных типов(для запросов на точное совпадение, на попадание в диапазон и для полнотекстового поиска). Хранилища были загружены в движок, а затем, для каждого хранилища были сгенерированы триста тысяч случайных значений соответствующих атрибутов. Затем, были сгенерированы пять тысяч поисковых запросов по этим атрибутам. После этого запросы были выполнены сначала тривиальным исполнителем, затем исполнителем с весами, и, наконец, автоконфигурируемым исполнителем. 
            
        В ходе тестирования считалось время выполнения всех поисковых запросов для одного исполнителя, оно делилось на количество запросов, тем самым, давая в результате среднее время исполнения запроса в серии. После каждой серии запросов результирующие выборки сохранялись и проверялись на равенство. Кроме того, для каждой серии запросов была посчитана дисперсия и стандартное отклонение.
        
        Тестирование массовой загрузки, в свою очередь, преследовало цель убедиться в достоинствах и недостатках обоих вариантов атомарного добавления документа.
        
        С этой целью, снова был создан движок базы данных, были созданы три хранилища разных типов(для запросов на точное совпадение, на попадание в диапазон и для полнотекстового поиска). Хранилища были загружены в движок, а затем, для каждого хранилища были сгенерированы триста тысяч случайных значений соответствующих атрибутов. Затем, были сгенерированы пять тысяч поисковых запросов. После, был начат сеанс массовой загрузки документов, в рамках которого к базе было применено десять тысяч изменений.
        
        После этого, были выполнены сгенерированные ранее поисковые запросы, а затем - изменения были физически применены к базе данных. После этого запросы были выполнены ещё раз. В ходе всего тестирования измерялось время выполнения каждого запроса и время физического применения изменения к базе данных. Были выстроены два графика зависимости времени выполнения операций в условиях массовой загрузки документов - для первой и второй реализации атомарного добавления документа.
    \subsection{Результаты тестирования}
        Реализованные тесты запускались на домашнем ноутбуке ASUS K43e, с процессором Intel Core i3 и восемью гигабайтами оперативной памяти. Цифры, указанные в описании выше продиктованы ограничениями вычислительных мощностей домашнего компьютера, поэтому и выбраны таковыми.
        Для трехсот тысяч документов, пяти тысяч запросов по трём атрибутам среднее время выполнения одного запроса в серии составляет:
        \begin{enumerate}
            \item Для алгоритма DumbExecutor - 21.3262 ms
            \item Для алгоритма SmartExecutor - 9.34  ms
            \item Для алгоритма TunableExecutor - 7.0384 ms 
        \end{enumerate}
        
        Алгоритм SmartExecutor запускался с параметром $threshold$ равным трём тысячам документам.
        
        Приведём графики, выстроенные в ходе тестирования двух вариантов атомарного добавления документа:
        
        \begin{figure}[H]
            \centering
            \includegraphics[height=0.4\textheight]{../pics/simpleTran.png}
            \caption{График зависимости времени выполнения операций в ходе сеанса массовой загрузки(первый вариант)}
            \label{simpleTran}
        \end{figure}
        
        \begin{figure}[H]
            \centering
            \includegraphics[height=0.4\textheight]{../pics/newTran.png}
            \caption{График зависимости времени выполнения операций в ходе сеанса массовой загрузки(второй вариант)}
            \label{newTran}
        \end{figure}
        
        Как видно, пик на рисунке \ref{simpleTran} соответствует простою системы при физическом применении изменений к базе данных(при операции $CommitTransaction$). А вот на рисунке \ref{newTran} пик уже отсутствует, однако видно увеличение времени выполнения запросов после фиксации изменений.
        
        \subsection{Выводы по третьей главе}
            В третьей главе приведено описание технологической платформы, на которой реализованы алгоритмы, описанные в предыдущей главе. Описана цель тестирования, поставлена задача и введены формальные показатели. Приведено описание тестовой инфраструктуры и её параметров. Приведены результаты тестирования и дана их интерпретация. 
    
\section*{Заключение}
    В ходе данной работы были поставлены задачи описать и реализовать различные алгоритмы выполнения поисковых запросов к колоночно-ориентированной базе данных. %про эффективность бы что-нибудь сболтнуть....
    
    Для этого была проанализирована предметная область, дана краткая историческая справка, приведено общее описание архитектуры колоночно-ориентированных баз данных. Были проанализированы аналогичные решения, поставлены задачи работы и даны требования к решению.
    
    Во второй главе были описаны алгоритмы выполнения поисковых запросов. Была описана архитектура базы данных Vindur и обозначено место разрабатываемых алгоримов в ней. Был приведен псевдокод алгоритмов с описанием вспомогательных процедур и функций. Кроме того, было приведено описание и псевдокод двух алгоритмов атомарного добавления документа в базу данных. Блок-схемы алгоритмов и диаграмма классов системы Vindur вынесены в приложения.
    
    В третьей главе дано описание и обоснование технологической платформы, использованных инструментов и инфраструктурных решений. Была поставлена задача тестирования разработанных алгоритмов, введены формальные показатели для сравнения и проведено сравнение. Были приведены результаты тестирования атомарного добавления документа, описаны достоинства и недостатки.
    
    Проект размещен в публичном репозитории по адресу https://github.com/cscenter/Vindur
    
    Примеры реализации отдельных алгоритмов и тестовой инфраструктуры также вынесены в приложения.

\bibliographystyle{ugost2008s}
\bibliography{diploma.bib}

\begin{landscape}
    \thispagestyle{empty}
    \section*{Приложение А. Диаграмма классов системы Vindur}
        \begin{figure}[H]
            \label{classes}
            \centering
            \includegraphics[height = 0.75\textheight]{../pics/diagram.png}
            \caption{Диаграмма классов системы Vindur.}
        \end{figure}
\end{landscape}

\section*{Приложение Б. Блок-схема алгоритма DumbExecutor}
    \begin{figure}[H]
        \label{dumbAlgo}
        \centering
        \includegraphics[height=0.9\textheight]{../pics/dumbExec.png}
        \caption{Блок-схема алгоритма DumbExecutor.}
    \end{figure}
\section*{Приложение В. Блок-схема алгоритма SmartExecutor}
    \begin{figure}[H]
        \centering
        \includegraphics[height=0.9\textheight]{../pics/smartExec.png}
        \caption{Блок-схема алгоритма SmartExecutor}
        \label{smartAlgo}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[height=0.9\textheight]{../pics/smartExecCheck.png}
        \caption{Блок-схема алгоритма SmartExecutor. Функция CheckManually.}
        \label{smartCheck}
    \end{figure}
\section*{Приложение Г. Блок-схема алгоритма TunableExecutor}
    \begin{figure}[H]
        \centering
        \includegraphics[height=0.9\textheight]{../pics/tunableExec.png}
        \caption{Блок-схема алгоритма TunableExecutor.}
        \label{smartCheck}
    \end{figure}
\section*{Приложение Д. Реализация алгоритма SmartExecutor}
    \inputminted[breaklines=true]{java}{../sources/SmartExecutor.java}
\section*{Приложение Е. Реализация тестовой инфраструктуры}
    \inputminted[breaklines=true]{java}{../sources/TuningTest.java}
\end{document}